{
  "family": "router",
  "split": "test",
  "overall": {
    "confidence_bin::high": {
      "precision": 1.0,
      "recall": 1.0,
      "f1-score": 1.0,
      "support": 10.0
    },
    "confidence_bin::low": {
      "precision": 1.0,
      "recall": 1.0,
      "f1-score": 1.0,
      "support": 10.0
    },
    "confidence_bin::medium": {
      "precision": 1.0,
      "recall": 1.0,
      "f1-score": 1.0,
      "support": 10.0
    },
    "constraint_dimension::causal": {
      "precision": 0.8,
      "recall": 0.8,
      "f1-score": 0.8,
      "support": 10.0
    },
    "constraint_dimension::goal": {
      "precision": 0.7,
      "recall": 0.7,
      "f1-score": 0.7,
      "support": 10.0
    },
    "constraint_dimension::other": {
      "precision": 0.75,
      "recall": 0.9,
      "f1-score": 0.8181818181818182,
      "support": 10.0
    },
    "constraint_dimension::policy": {
      "precision": 0.7272727272727273,
      "recall": 0.8,
      "f1-score": 0.7619047619047619,
      "support": 10.0
    },
    "constraint_dimension::state": {
      "precision": 0.7777777777777778,
      "recall": 0.7,
      "f1-score": 0.7368421052631579,
      "support": 10.0
    },
    "constraint_dimension::value": {
      "precision": 1.0,
      "recall": 0.8,
      "f1-score": 0.8888888888888888,
      "support": 10.0
    },
    "context_tag::finance": {
      "precision": 0.7272727272727273,
      "recall": 0.8,
      "f1-score": 0.7619047619047619,
      "support": 10.0
    },
    "context_tag::food": {
      "precision": 1.0,
      "recall": 0.9,
      "f1-score": 0.9473684210526315,
      "support": 10.0
    },
    "context_tag::general": {
      "precision": 1.0,
      "recall": 0.8,
      "f1-score": 0.8888888888888888,
      "support": 10.0
    },
    "context_tag::health": {
      "precision": 0.9,
      "recall": 0.9,
      "f1-score": 0.9,
      "support": 10.0
    },
    "context_tag::social": {
      "precision": 1.0,
      "recall": 1.0,
      "f1-score": 1.0,
      "support": 10.0
    },
    "context_tag::tech": {
      "precision": 0.8181818181818182,
      "recall": 0.9,
      "f1-score": 0.8571428571428571,
      "support": 10.0
    },
    "context_tag::travel": {
      "precision": 0.8333333333333334,
      "recall": 1.0,
      "f1-score": 0.9090909090909091,
      "support": 10.0
    },
    "context_tag::work": {
      "precision": 0.8333333333333334,
      "recall": 1.0,
      "f1-score": 0.9090909090909091,
      "support": 10.0
    },
    "decay_profile::fast": {
      "precision": 0.9090909090909091,
      "recall": 1.0,
      "f1-score": 0.9523809523809523,
      "support": 10.0
    },
    "decay_profile::medium": {
      "precision": 0.8333333333333334,
      "recall": 1.0,
      "f1-score": 0.9090909090909091,
      "support": 10.0
    },
    "decay_profile::slow": {
      "precision": 0.8,
      "recall": 0.8,
      "f1-score": 0.8,
      "support": 10.0
    },
    "decay_profile::very_fast": {
      "precision": 0.9,
      "recall": 0.9,
      "f1-score": 0.9,
      "support": 10.0
    },
    "decay_profile::very_slow": {
      "precision": 0.8888888888888888,
      "recall": 0.8,
      "f1-score": 0.8421052631578947,
      "support": 10.0
    },
    "importance_bin::high": {
      "precision": 1.0,
      "recall": 0.9,
      "f1-score": 0.9473684210526315,
      "support": 10.0
    },
    "importance_bin::low": {
      "precision": 0.7692307692307693,
      "recall": 1.0,
      "f1-score": 0.8695652173913043,
      "support": 10.0
    },
    "importance_bin::medium": {
      "precision": 0.875,
      "recall": 0.7,
      "f1-score": 0.7777777777777778,
      "support": 10.0
    },
    "memory_type::constraint": {
      "precision": 0.9,
      "recall": 0.9,
      "f1-score": 0.9,
      "support": 10.0
    },
    "memory_type::conversation": {
      "precision": 0.6666666666666666,
      "recall": 0.6,
      "f1-score": 0.631578947368421,
      "support": 10.0
    },
    "memory_type::episodic_event": {
      "precision": 0.9,
      "recall": 0.9,
      "f1-score": 0.9,
      "support": 10.0
    },
    "memory_type::hypothesis": {
      "precision": 0.8333333333333334,
      "recall": 1.0,
      "f1-score": 0.9090909090909091,
      "support": 10.0
    },
    "memory_type::knowledge": {
      "precision": 1.0,
      "recall": 0.7,
      "f1-score": 0.8235294117647058,
      "support": 10.0
    },
    "memory_type::message": {
      "precision": 0.8,
      "recall": 0.4,
      "f1-score": 0.5333333333333333,
      "support": 10.0
    },
    "memory_type::observation": {
      "precision": 0.7,
      "recall": 0.7,
      "f1-score": 0.7,
      "support": 10.0
    },
    "memory_type::plan": {
      "precision": 1.0,
      "recall": 0.8,
      "f1-score": 0.8888888888888888,
      "support": 10.0
    },
    "memory_type::preference": {
      "precision": 0.4444444444444444,
      "recall": 0.4,
      "f1-score": 0.42105263157894735,
      "support": 10.0
    },
    "memory_type::procedure": {
      "precision": 0.7272727272727273,
      "recall": 0.8,
      "f1-score": 0.7619047619047619,
      "support": 10.0
    },
    "memory_type::reasoning_step": {
      "precision": 0.45454545454545453,
      "recall": 1.0,
      "f1-score": 0.625,
      "support": 10.0
    },
    "memory_type::scratch": {
      "precision": 1.0,
      "recall": 0.8,
      "f1-score": 0.8888888888888888,
      "support": 10.0
    },
    "memory_type::semantic_fact": {
      "precision": 0.5714285714285714,
      "recall": 0.4,
      "f1-score": 0.47058823529411764,
      "support": 10.0
    },
    "memory_type::task_state": {
      "precision": 0.4117647058823529,
      "recall": 0.7,
      "f1-score": 0.5185185185185185,
      "support": 10.0
    },
    "memory_type::tool_result": {
      "precision": 1.0,
      "recall": 0.9,
      "f1-score": 0.9473684210526315,
      "support": 10.0
    },
    "query_domain::finance": {
      "precision": 0.9900990099009901,
      "recall": 1.0,
      "f1-score": 0.9950248756218906,
      "support": 500.0
    },
    "query_domain::food": {
      "precision": 1.0,
      "recall": 0.9,
      "f1-score": 0.9473684210526315,
      "support": 10.0
    },
    "query_domain::general": {
      "precision": 1.0,
      "recall": 0.7,
      "f1-score": 0.8235294117647058,
      "support": 10.0
    },
    "query_domain::health": {
      "precision": 1.0,
      "recall": 1.0,
      "f1-score": 1.0,
      "support": 10.0
    },
    "query_domain::social": {
      "precision": 1.0,
      "recall": 0.7,
      "f1-score": 0.8235294117647058,
      "support": 10.0
    },
    "query_domain::tech": {
      "precision": 1.0,
      "recall": 0.7,
      "f1-score": 0.8235294117647058,
      "support": 10.0
    },
    "query_domain::travel": {
      "precision": 1.0,
      "recall": 0.8,
      "f1-score": 0.8888888888888888,
      "support": 10.0
    },
    "query_domain::work": {
      "precision": 0.8888888888888888,
      "recall": 0.8,
      "f1-score": 0.8421052631578947,
      "support": 10.0
    },
    "query_intent::constraint_check": {
      "precision": 1.0,
      "recall": 0.9,
      "f1-score": 0.9473684210526315,
      "support": 10.0
    },
    "query_intent::conversation": {
      "precision": 0.7142857142857143,
      "recall": 1.0,
      "f1-score": 0.8333333333333334,
      "support": 10.0
    },
    "query_intent::factual": {
      "precision": 1.0,
      "recall": 0.7,
      "f1-score": 0.8235294117647058,
      "support": 10.0
    },
    "query_intent::planning": {
      "precision": 1.0,
      "recall": 0.7,
      "f1-score": 0.8235294117647058,
      "support": 10.0
    },
    "query_intent::tool_query": {
      "precision": 0.8333333333333334,
      "recall": 1.0,
      "f1-score": 0.9090909090909091,
      "support": 10.0
    },
    "salience_bin::high": {
      "precision": 0.7272727272727273,
      "recall": 0.8,
      "f1-score": 0.7619047619047619,
      "support": 10.0
    },
    "salience_bin::low": {
      "precision": 0.8,
      "recall": 0.8,
      "f1-score": 0.8,
      "support": 10.0
    },
    "salience_bin::medium": {
      "precision": 1.0,
      "recall": 0.9,
      "f1-score": 0.9473684210526315,
      "support": 10.0
    },
    "accuracy": 0.9095238095238095,
    "macro avg": {
      "precision": 0.8608223427673362,
      "recall": 0.8303571428571429,
      "f1-score": 0.8354899314986478,
      "support": 1050.0
    },
    "weighted avg": {
      "precision": 0.9211514540963747,
      "recall": 0.9095238095238095,
      "f1-score": 0.9099395720894944,
      "support": 1050.0
    }
  },
  "per_task": {
    "confidence_bin": {
      "high": {
        "precision": 1.0,
        "recall": 1.0,
        "f1-score": 1.0,
        "support": 10.0
      },
      "low": {
        "precision": 1.0,
        "recall": 1.0,
        "f1-score": 1.0,
        "support": 10.0
      },
      "medium": {
        "precision": 1.0,
        "recall": 1.0,
        "f1-score": 1.0,
        "support": 10.0
      },
      "accuracy": 1.0,
      "macro avg": {
        "precision": 1.0,
        "recall": 1.0,
        "f1-score": 1.0,
        "support": 30.0
      },
      "weighted avg": {
        "precision": 1.0,
        "recall": 1.0,
        "f1-score": 1.0,
        "support": 30.0
      }
    },
    "constraint_dimension": {
      "causal": {
        "precision": 0.8,
        "recall": 0.8,
        "f1-score": 0.8,
        "support": 10.0
      },
      "goal": {
        "precision": 0.7,
        "recall": 0.7,
        "f1-score": 0.7,
        "support": 10.0
      },
      "other": {
        "precision": 0.75,
        "recall": 0.9,
        "f1-score": 0.8181818181818182,
        "support": 10.0
      },
      "policy": {
        "precision": 0.8,
        "recall": 0.8,
        "f1-score": 0.8,
        "support": 10.0
      },
      "state": {
        "precision": 0.7777777777777778,
        "recall": 0.7,
        "f1-score": 0.7368421052631579,
        "support": 10.0
      },
      "value": {
        "precision": 1.0,
        "recall": 0.8,
        "f1-score": 0.8888888888888888,
        "support": 10.0
      },
      "micro avg": {
        "precision": 0.7966101694915254,
        "recall": 0.7833333333333333,
        "f1-score": 0.7899159663865546,
        "support": 60.0
      },
      "macro avg": {
        "precision": 0.8046296296296296,
        "recall": 0.7833333333333333,
        "f1-score": 0.7906521353889775,
        "support": 60.0
      },
      "weighted avg": {
        "precision": 0.8046296296296297,
        "recall": 0.7833333333333333,
        "f1-score": 0.7906521353889775,
        "support": 60.0
      }
    },
    "context_tag": {
      "finance": {
        "precision": 0.8,
        "recall": 0.8,
        "f1-score": 0.8,
        "support": 10.0
      },
      "food": {
        "precision": 1.0,
        "recall": 0.9,
        "f1-score": 0.9473684210526315,
        "support": 10.0
      },
      "general": {
        "precision": 1.0,
        "recall": 0.8,
        "f1-score": 0.8888888888888888,
        "support": 10.0
      },
      "health": {
        "precision": 0.9,
        "recall": 0.9,
        "f1-score": 0.9,
        "support": 10.0
      },
      "social": {
        "precision": 1.0,
        "recall": 1.0,
        "f1-score": 1.0,
        "support": 10.0
      },
      "tech": {
        "precision": 0.9,
        "recall": 0.9,
        "f1-score": 0.9,
        "support": 10.0
      },
      "travel": {
        "precision": 0.9090909090909091,
        "recall": 1.0,
        "f1-score": 0.9523809523809523,
        "support": 10.0
      },
      "work": {
        "precision": 0.8333333333333334,
        "recall": 1.0,
        "f1-score": 0.9090909090909091,
        "support": 10.0
      },
      "accuracy": 0.9125,
      "macro avg": {
        "precision": 0.9178030303030303,
        "recall": 0.9125000000000001,
        "f1-score": 0.9122161464266727,
        "support": 80.0
      },
      "weighted avg": {
        "precision": 0.9178030303030302,
        "recall": 0.9125,
        "f1-score": 0.9122161464266727,
        "support": 80.0
      }
    },
    "decay_profile": {
      "fast": {
        "precision": 0.9090909090909091,
        "recall": 1.0,
        "f1-score": 0.9523809523809523,
        "support": 10.0
      },
      "medium": {
        "precision": 0.8333333333333334,
        "recall": 1.0,
        "f1-score": 0.9090909090909091,
        "support": 10.0
      },
      "slow": {
        "precision": 0.8888888888888888,
        "recall": 0.8,
        "f1-score": 0.8421052631578947,
        "support": 10.0
      },
      "very_fast": {
        "precision": 0.9,
        "recall": 0.9,
        "f1-score": 0.9,
        "support": 10.0
      },
      "very_slow": {
        "precision": 1.0,
        "recall": 0.8,
        "f1-score": 0.8888888888888888,
        "support": 10.0
      },
      "accuracy": 0.9,
      "macro avg": {
        "precision": 0.9062626262626263,
        "recall": 0.9,
        "f1-score": 0.8984932027037289,
        "support": 50.0
      },
      "weighted avg": {
        "precision": 0.9062626262626261,
        "recall": 0.9,
        "f1-score": 0.8984932027037289,
        "support": 50.0
      }
    },
    "importance_bin": {
      "high": {
        "precision": 1.0,
        "recall": 0.9,
        "f1-score": 0.9473684210526315,
        "support": 10.0
      },
      "low": {
        "precision": 0.7692307692307693,
        "recall": 1.0,
        "f1-score": 0.8695652173913043,
        "support": 10.0
      },
      "medium": {
        "precision": 1.0,
        "recall": 0.7,
        "f1-score": 0.8235294117647058,
        "support": 10.0
      },
      "micro avg": {
        "precision": 0.896551724137931,
        "recall": 0.8666666666666667,
        "f1-score": 0.8813559322033898,
        "support": 30.0
      },
      "macro avg": {
        "precision": 0.923076923076923,
        "recall": 0.8666666666666666,
        "f1-score": 0.8801543500695472,
        "support": 30.0
      },
      "weighted avg": {
        "precision": 0.9230769230769231,
        "recall": 0.8666666666666667,
        "f1-score": 0.8801543500695472,
        "support": 30.0
      }
    },
    "memory_type": {
      "constraint": {
        "precision": 0.9,
        "recall": 0.9,
        "f1-score": 0.9,
        "support": 10.0
      },
      "conversation": {
        "precision": 0.6666666666666666,
        "recall": 0.6,
        "f1-score": 0.631578947368421,
        "support": 10.0
      },
      "episodic_event": {
        "precision": 1.0,
        "recall": 0.9,
        "f1-score": 0.9473684210526315,
        "support": 10.0
      },
      "hypothesis": {
        "precision": 0.8333333333333334,
        "recall": 1.0,
        "f1-score": 0.9090909090909091,
        "support": 10.0
      },
      "knowledge": {
        "precision": 1.0,
        "recall": 0.7,
        "f1-score": 0.8235294117647058,
        "support": 10.0
      },
      "message": {
        "precision": 0.8,
        "recall": 0.4,
        "f1-score": 0.5333333333333333,
        "support": 10.0
      },
      "observation": {
        "precision": 0.7,
        "recall": 0.7,
        "f1-score": 0.7,
        "support": 10.0
      },
      "plan": {
        "precision": 1.0,
        "recall": 0.8,
        "f1-score": 0.8888888888888888,
        "support": 10.0
      },
      "preference": {
        "precision": 0.4444444444444444,
        "recall": 0.4,
        "f1-score": 0.42105263157894735,
        "support": 10.0
      },
      "procedure": {
        "precision": 0.8,
        "recall": 0.8,
        "f1-score": 0.8,
        "support": 10.0
      },
      "reasoning_step": {
        "precision": 0.47619047619047616,
        "recall": 1.0,
        "f1-score": 0.6451612903225806,
        "support": 10.0
      },
      "scratch": {
        "precision": 1.0,
        "recall": 0.8,
        "f1-score": 0.8888888888888888,
        "support": 10.0
      },
      "semantic_fact": {
        "precision": 0.5714285714285714,
        "recall": 0.4,
        "f1-score": 0.47058823529411764,
        "support": 10.0
      },
      "task_state": {
        "precision": 0.4375,
        "recall": 0.7,
        "f1-score": 0.5384615384615384,
        "support": 10.0
      },
      "tool_result": {
        "precision": 1.0,
        "recall": 0.9,
        "f1-score": 0.9473684210526315,
        "support": 10.0
      },
      "accuracy": 0.7333333333333333,
      "macro avg": {
        "precision": 0.7753042328042329,
        "recall": 0.7333333333333333,
        "f1-score": 0.7363540611398397,
        "support": 150.0
      },
      "weighted avg": {
        "precision": 0.7753042328042328,
        "recall": 0.7333333333333333,
        "f1-score": 0.7363540611398396,
        "support": 150.0
      }
    },
    "query_domain": {
      "finance": {
        "precision": 0.9900990099009901,
        "recall": 1.0,
        "f1-score": 0.9950248756218906,
        "support": 500.0
      },
      "food": {
        "precision": 1.0,
        "recall": 0.9,
        "f1-score": 0.9473684210526315,
        "support": 10.0
      },
      "general": {
        "precision": 1.0,
        "recall": 0.7,
        "f1-score": 0.8235294117647058,
        "support": 10.0
      },
      "health": {
        "precision": 1.0,
        "recall": 1.0,
        "f1-score": 1.0,
        "support": 10.0
      },
      "social": {
        "precision": 1.0,
        "recall": 0.7,
        "f1-score": 0.8235294117647058,
        "support": 10.0
      },
      "tech": {
        "precision": 1.0,
        "recall": 0.7,
        "f1-score": 0.8235294117647058,
        "support": 10.0
      },
      "travel": {
        "precision": 1.0,
        "recall": 0.8,
        "f1-score": 0.8888888888888888,
        "support": 10.0
      },
      "work": {
        "precision": 0.8888888888888888,
        "recall": 0.8,
        "f1-score": 0.8421052631578947,
        "support": 10.0
      },
      "micro avg": {
        "precision": 0.9893238434163701,
        "recall": 0.9754385964912281,
        "f1-score": 0.9823321554770318,
        "support": 570.0
      },
      "macro avg": {
        "precision": 0.9848734873487348,
        "recall": 0.825,
        "f1-score": 0.8929969605019279,
        "support": 570.0
      },
      "weighted avg": {
        "precision": 0.9893656032269894,
        "recall": 0.9754385964912281,
        "f1-score": 0.9807051682366326,
        "support": 570.0
      }
    },
    "query_intent": {
      "constraint_check": {
        "precision": 1.0,
        "recall": 0.9,
        "f1-score": 0.9473684210526315,
        "support": 10.0
      },
      "conversation": {
        "precision": 0.7142857142857143,
        "recall": 1.0,
        "f1-score": 0.8333333333333334,
        "support": 10.0
      },
      "factual": {
        "precision": 1.0,
        "recall": 0.7,
        "f1-score": 0.8235294117647058,
        "support": 10.0
      },
      "planning": {
        "precision": 1.0,
        "recall": 0.7,
        "f1-score": 0.8235294117647058,
        "support": 10.0
      },
      "tool_query": {
        "precision": 0.8333333333333334,
        "recall": 1.0,
        "f1-score": 0.9090909090909091,
        "support": 10.0
      },
      "micro avg": {
        "precision": 0.8775510204081632,
        "recall": 0.86,
        "f1-score": 0.8686868686868687,
        "support": 50.0
      },
      "macro avg": {
        "precision": 0.9095238095238095,
        "recall": 0.86,
        "f1-score": 0.867370297401257,
        "support": 50.0
      },
      "weighted avg": {
        "precision": 0.9095238095238095,
        "recall": 0.86,
        "f1-score": 0.867370297401257,
        "support": 50.0
      }
    },
    "salience_bin": {
      "high": {
        "precision": 0.7272727272727273,
        "recall": 0.8,
        "f1-score": 0.7619047619047619,
        "support": 10.0
      },
      "low": {
        "precision": 0.8,
        "recall": 0.8,
        "f1-score": 0.8,
        "support": 10.0
      },
      "medium": {
        "precision": 1.0,
        "recall": 0.9,
        "f1-score": 0.9473684210526315,
        "support": 10.0
      },
      "accuracy": 0.8333333333333334,
      "macro avg": {
        "precision": 0.8424242424242424,
        "recall": 0.8333333333333334,
        "f1-score": 0.8364243943191312,
        "support": 30.0
      },
      "weighted avg": {
        "precision": 0.8424242424242424,
        "recall": 0.8333333333333334,
        "f1-score": 0.8364243943191312,
        "support": 30.0
      }
    }
  }
}