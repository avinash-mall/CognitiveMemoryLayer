# =============================================================================
# Cognitive Memory Layer (CML) — Environment Configuration
# =============================================================================
# Copy this file to .env and set values for your environment.
# [Required] = must be set for the feature to work.
# [Optional] = has a default; unset to use default.
# =============================================================================

# =============================================================================
# PART A — CML SERVER (API)
# =============================================================================
# The server reads settings via pydantic-settings. Nested keys use double
# underscore: SECTION__KEY (e.g. DATABASE__POSTGRES_URL).
# =============================================================================

# -----------------------------------------------------------------------------
# A.1 Database
# -----------------------------------------------------------------------------
# Values below match docker/docker-compose.yml for local development.

# [Required] PostgreSQL connection. Must use async driver.
# Format: postgresql+asyncpg://user:password@host:port/dbname
DATABASE__POSTGRES_URL=postgresql+asyncpg://memory:memory@localhost/memory

# [Optional] Neo4j (bolt). Omit or disable if not using graph features.
DATABASE__NEO4J_URL=bolt://localhost:7687
DATABASE__NEO4J_USER=neo4j
# [Required when Neo4j URL is not localhost] e.g. cloud or secured instance
DATABASE__NEO4J_PASSWORD=password

# [Optional] Redis URL for caching/sessions (default: redis://localhost:6379)
DATABASE__REDIS_URL=redis://localhost:6379

# -----------------------------------------------------------------------------
# A.2 Authentication
# -----------------------------------------------------------------------------
# Use test-key for local dev so py-cml integration/e2e tests (CML_TEST_API_KEY
# default) work without extra config. For production, set strong secrets.

# [Required for API access] API key for memory operations (X-API-Key header)
AUTH__API_KEY=test-key

# [Optional] Admin API key for dashboard, consolidate, run_forgetting, list_tenants
AUTH__ADMIN_API_KEY=test-key

# [Optional] Default tenant when request does not send X-Tenant-ID (default: default)
AUTH__DEFAULT_TENANT_ID=default

# -----------------------------------------------------------------------------
# A.3 LLM
# -----------------------------------------------------------------------------
# Provider: openai | vllm | ollama | gemini | claude

# [Optional] LLM provider (default: openai)
LLM__PROVIDER=openai
# [Optional] Model name (default: gpt-4o-mini)
LLM__MODEL=gpt-4o-mini
# [Optional] API key; can fall back to OPENAI_API_KEY if unset
LLM__API_KEY=your-openai-key
# [Optional] Base URL for vLLM / Ollama / OpenAI-compatible proxy
# LLM__BASE_URL=
# Legacy aliases (tests/examples): LLM__VLLM_BASE_URL, VLLM_BASE_URL

# Example — vLLM local:
# LLM__PROVIDER=vllm
# LLM__MODEL=meta-llama/Llama-3.2-1B-Instruct
# LLM__BASE_URL=http://localhost:8000/v1

# Example — Ollama local (Docker API → host: LLM__BASE_URL=http://host.docker.internal:11434/v1)
# LLM__PROVIDER=ollama
# LLM__MODEL=llama3.2
# LLM__BASE_URL=http://localhost:11434/v1

# -----------------------------------------------------------------------------
# A.4 Embeddings
# -----------------------------------------------------------------------------
# Provider: openai | local | vllm | ollama

# [Optional] Embedding provider (default: openai)
EMBEDDING__PROVIDER=openai
# [Optional] Model name (default: text-embedding-3-small)
EMBEDDING__MODEL=text-embedding-3-small
# [Optional] Vector dimension; must match DB after migrations (default: 1536)
EMBEDDING__DIMENSIONS=1536
# [Optional] API key; can fall back to OPENAI_API_KEY if unset
EMBEDDING__API_KEY=your-openai-key
# [Optional] Local model when provider=local (default: all-MiniLM-L6-v2)
# EMBEDDING__LOCAL_MODEL=all-MiniLM-L6-v2
# [Optional] Base URL for vLLM/Ollama or OpenAI-compatible embedding endpoint
# EMBEDDING__BASE_URL=

# Changing EMBEDDING__DIMENSIONS requires DB schema change (drop/recreate or new migration).

# Example — local embeddings:
# EMBEDDING__PROVIDER=local
# EMBEDDING__MODEL=all-MiniLM-L6-v2
# EMBEDDING__DIMENSIONS=384

# Example — Ollama embeddings (e.g. mxbai-embed-large: 1024 dims):
# EMBEDDING__PROVIDER=ollama
# EMBEDDING__MODEL=mxbai-embed-large:latest
# EMBEDDING__DIMENSIONS=1024
# EMBEDDING__BASE_URL=http://localhost:11434/v1

# -----------------------------------------------------------------------------
# A.5 Application (top-level server settings)
# -----------------------------------------------------------------------------

# [Optional] Application name (default: CognitiveMemoryLayer)
# APP_NAME=CognitiveMemoryLayer

# [Optional] Debug mode: hot reload (main.py), permissive CORS (default: false)
# DEBUG=false

# [Optional] CORS allowed origins. JSON array or implementation-specific list format.
# Unset = use default list; DEBUG=true allows "*".
# CORS_ORIGINS=["http://localhost:3000","http://localhost:8080"]

# =============================================================================
# PART B — PY-CML CLIENT (Python SDK)
# =============================================================================
# Used when connecting to the CML API from Python. Loaded from env or .env
# (dotenv) with CML_ prefix. Constructor args override env.
# =============================================================================

# [Required for authenticated requests] API key (sent as X-API-Key)
CML_API_KEY=your-api-key-here

# [Optional] CML server base URL (default: http://localhost:8000)
CML_BASE_URL=http://localhost:8000

# [Optional] Tenant ID for multi-tenant isolation (default: default)
CML_TENANT_ID=default

# [Optional] Request timeout in seconds (default: 30.0)
# CML_TIMEOUT=30.0

# [Optional] Max retries for transient failures (default: 3)
# CML_MAX_RETRIES=3

# [Optional] Base delay between retries in seconds (default: 1.0)
# CML_RETRY_DELAY=1.0

# [Optional] Admin API key for consolidate, run_forgetting, list_tenants
# CML_ADMIN_API_KEY=your-admin-key-here

# [Optional] Verify SSL certificates (default: true). Use false only for local/dev.
# CML_VERIFY_SSL=true

# =============================================================================
# PART C — FALLBACK API KEYS
# =============================================================================
# Used by server when LLM__API_KEY or EMBEDDING__API_KEY are unset (e.g. OpenAI).
# =============================================================================

# [Optional] Fallback for OpenAI provider (LLM and/or Embedding)
# OPENAI_API_KEY=your-openai-key

# =============================================================================
# PART D — EXAMPLES & SCRIPTS
# =============================================================================
# These appear in examples/ and tests; not part of core server or py-cml config.
# =============================================================================

# [Optional] Examples: CML API URL (default in examples: http://localhost:8000)
# MEMORY_API_URL=http://localhost:8000

# [Optional] Examples: CML API key (often same as AUTH__API_KEY)
# MEMORY_API_KEY=your-api-key

# [Optional] Examples: request timeout in seconds (e.g. ollama_chat_test.py)
# MEMORY_API_TIMEOUT=120

# [Optional] Examples: Ollama base URL (default: http://localhost:11434/v1)
# OLLAMA_BASE_URL=http://localhost:11434/v1

# [Optional] Examples: Ollama model (or use LLM__MODEL)
# OLLAMA_MODEL=llama3.2

# [Optional] Examples/tool-calling: Anthropic API key
# ANTHROPIC_API_KEY=your-anthropic-key

# =============================================================================
# PART E — EMBEDDED MODE (py-cml)
# =============================================================================
# EmbeddedCognitiveMemoryLayer uses EmbeddedConfig. These are not read from
# .env by default; set them in code when building EmbeddedConfig. Shown here
# for reference.
# =============================================================================
#
#   storage_mode: "lite" | "standard" | "full"   (default: lite)
#   tenant_id: str                                (default: default)
#   database.postgres_url                         (default: sqlite+aiosqlite:///cml_memory.db)
#   database.neo4j_url, neo4j_user, neo4j_password, redis_url
#   embedding.provider: "openai"|"local"|"vllm"   embedding.model, dimensions, api_key, base_url
#   llm.provider: "openai"|"vllm"|"ollama"|"gemini"|"claude"   llm.model, api_key, base_url
#   auto_consolidate: bool                       (default: False)
#   auto_forget: bool                             (default: False)
#
# =============================================================================

# =============================================================================
# PART F — DEVELOPMENT & TESTING
# =============================================================================

# [Optional] Use existing Postgres from env instead of testcontainers (integration tests)
# USE_ENV_DB=1
# DATABASE__POSTGRES_URL=postgresql+asyncpg://...
